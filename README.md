# ğŸ›°ï¸ Drone Detection Dashboard

This project is a Flask-based web application designed to detect drones in uploaded videos or images using a custom-trained YOLOv8 model. Users can upload footage through the dashboard, after which the app automatically extracts frames, performs drone detection, and visually annotates the results. The interface uses a modern dark theme and supports both image and video processing.

---

## ğŸš€ Features

The dashboard includes the following main features:

* ğŸ“¤ Upload support for both video files (such as `.mp4`, `.avi`) and image files (such as `.jpg`, `.png`)
* ğŸï¸ Automatic frame extraction from uploaded videos
* ğŸ¯ Drone detection using a custom-trained YOLOv8 model
* ğŸ–¼ï¸ Annotated frames showing bounding boxes around detected drones
* ğŸ“Š Detection summary showing how many frames had drone detections
* ğŸ” Click-to-view previews for both original and annotated frames
* ğŸ–¥ï¸ Clean, responsive, dark-themed UI

---

## ğŸ› ï¸ Tech Stack

**ğŸ”§ Backend Technologies:**

The backend is powered by Flask and a YOLOv8-based detection pipeline:

* ğŸ§ª Flask â€“ for routing, uploads, and backend logic
* ğŸ¤– YOLOv8 (via Ultralytics) â€“ to load and apply the custom-trained model
* ğŸ”¥ PyTorch â€“ the deep learning engine behind YOLOv8
* ğŸ‘ï¸ OpenCV â€“ used to draw detection bounding boxes on images
* ğŸ Python libraries â€“ such as `imageio` (frame extraction), `Pillow` (image handling), `requests` (model download), and standard modules like `os`, `uuid`, etc.

**ğŸ¨ Frontend Technologies:**

The frontend is built with:

* ğŸ§± HTML5 and ğŸ¨ CSS3 â€“ for the structure and styling of the dashboard
* âš¡ JavaScript â€“ uses the Fetch API for dynamic server communication

---

## ğŸ“ Project Structure

Here is the folder structure of the project:

â”œâ”€â”€ app.py                         # Flask backend server
â”œâ”€â”€ detector.py                    # YOLOv8 object detection logic
â”œâ”€â”€ download_model.py              # Script to download YOLOv8n base model
â”œâ”€â”€ downloadCustomModel.py         # Script to download the custom-trained                                        model
â”œâ”€â”€ requirements.txt               # Required Python dependencies
â”œâ”€â”€ models/                       
â”‚   â”œâ”€â”€ 2_best.pt                  # Custom-trained YOLOv8 model (final                                           version)
â”‚   â””â”€â”€ yolov8n.pt                 # Base YOLOv8n model (from Ultralytics)

â”œâ”€â”€ static/                      
â”‚   â”œâ”€â”€ annotated_frames/          # YOLO-annotated output images
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css              # Dashboard styling
â”‚   â”œâ”€â”€ frames/                    # Extracted frames from uploaded media
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â””â”€â”€ script.js              # Frontend logic (media display, zoom, etc.)
â”‚   â””â”€â”€ uploads/                   # Uploaded raw media files
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                 # Main dashboard layout (HTML template)
â””â”€â”€ __pycache__/                   # Auto-generated Python bytecode cache

---

## âš™ï¸ Setup Instructions

1. ğŸ§© Clone the repository:
   `git clone https://github.com/your-username/video_frame_extractor.git`

2. ğŸ“ Navigate into the project folder:
   `cd video_frame_extractor`

3. ğŸ“¦ Install dependencies:
   `pip install -r requirements.txt`

4. â¬‡ï¸ Download the model (if not already present):
   `python downloadCustomModel.py`

5. ğŸ› ï¸ Run the Flask app:
   `python app.py`

6. ğŸŒ Open your browser and visit:
   `http://127.0.0.1:5000`

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See the `LICENSE` file for more details.
